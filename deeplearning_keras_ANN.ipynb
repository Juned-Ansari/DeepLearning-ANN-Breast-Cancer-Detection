{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function seaborn.categorical.countplot(x=None, y=None, hue=None, data=None, order=None, hue_order=None, orient=None, color=None, palette=None, saturation=0.75, dodge=True, ax=None, **kwargs)>"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df['diagnosis'],label=\"Count\")\n",
    "sns.countplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data['Unnamed: 32']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:, 2:].values\n",
    "y = data.iloc[:, 1].values\n",
    "\n",
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, random_state = 0)\n",
    "\n",
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(activation=\"relu\", input_dim=30, units=16, kernel_initializer=\"uniform\"))\n",
    "# Adding dropout to prevent overfitting\n",
    "classifier.add(Dropout(rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(activation=\"relu\", units=16, kernel_initializer=\"uniform\"))\n",
    "# Adding dropout to prevent overfitting\n",
    "classifier.add(Dropout(rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "classifier.add(Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "512/512 [==============================] - 4s 8ms/step - loss: 0.6927 - accuracy: 0.6270\n",
      "Epoch 2/150\n",
      "512/512 [==============================] - 0s 85us/step - loss: 0.6919 - accuracy: 0.6289\n",
      "Epoch 3/150\n",
      "512/512 [==============================] - 0s 87us/step - loss: 0.6912 - accuracy: 0.6289\n",
      "Epoch 4/150\n",
      "512/512 [==============================] - 0s 88us/step - loss: 0.6903 - accuracy: 0.6289\n",
      "Epoch 5/150\n",
      "512/512 [==============================] - 0s 82us/step - loss: 0.6895 - accuracy: 0.6289\n",
      "Epoch 6/150\n",
      "512/512 [==============================] - 0s 85us/step - loss: 0.6887 - accuracy: 0.6289\n",
      "Epoch 7/150\n",
      "512/512 [==============================] - 0s 85us/step - loss: 0.6878 - accuracy: 0.6289\n",
      "Epoch 8/150\n",
      "512/512 [==============================] - 0s 85us/step - loss: 0.6868 - accuracy: 0.6289\n",
      "Epoch 9/150\n",
      "512/512 [==============================] - 0s 84us/step - loss: 0.6854 - accuracy: 0.6289\n",
      "Epoch 10/150\n",
      "512/512 [==============================] - 0s 81us/step - loss: 0.6839 - accuracy: 0.6289\n",
      "Epoch 11/150\n",
      "512/512 [==============================] - 0s 86us/step - loss: 0.6823 - accuracy: 0.6289\n",
      "Epoch 12/150\n",
      "512/512 [==============================] - 0s 85us/step - loss: 0.6806 - accuracy: 0.6289\n",
      "Epoch 13/150\n",
      "512/512 [==============================] - 0s 81us/step - loss: 0.6781 - accuracy: 0.6289\n",
      "Epoch 14/150\n",
      "512/512 [==============================] - 0s 84us/step - loss: 0.6752 - accuracy: 0.6289\n",
      "Epoch 15/150\n",
      "512/512 [==============================] - 0s 85us/step - loss: 0.6712 - accuracy: 0.6289\n",
      "Epoch 16/150\n",
      "512/512 [==============================] - 0s 95us/step - loss: 0.6674 - accuracy: 0.6289\n",
      "Epoch 17/150\n",
      "512/512 [==============================] - 0s 83us/step - loss: 0.6627 - accuracy: 0.6289\n",
      "Epoch 18/150\n",
      "512/512 [==============================] - 0s 84us/step - loss: 0.6578 - accuracy: 0.6289\n",
      "Epoch 19/150\n",
      "512/512 [==============================] - 0s 85us/step - loss: 0.6532 - accuracy: 0.6289\n",
      "Epoch 20/150\n",
      "512/512 [==============================] - 0s 84us/step - loss: 0.6476 - accuracy: 0.6289\n",
      "Epoch 21/150\n",
      "512/512 [==============================] - 0s 83us/step - loss: 0.6424 - accuracy: 0.6289\n",
      "Epoch 22/150\n",
      "512/512 [==============================] - 0s 88us/step - loss: 0.6369 - accuracy: 0.6289\n",
      "Epoch 23/150\n",
      "512/512 [==============================] - 0s 85us/step - loss: 0.6326 - accuracy: 0.6289\n",
      "Epoch 24/150\n",
      "512/512 [==============================] - 0s 83us/step - loss: 0.6260 - accuracy: 0.6289\n",
      "Epoch 25/150\n",
      "512/512 [==============================] - 0s 81us/step - loss: 0.6213 - accuracy: 0.6289\n",
      "Epoch 26/150\n",
      "512/512 [==============================] - 0s 87us/step - loss: 0.6173 - accuracy: 0.6289\n",
      "Epoch 27/150\n",
      "512/512 [==============================] - 0s 83us/step - loss: 0.6143 - accuracy: 0.6289\n",
      "Epoch 28/150\n",
      "512/512 [==============================] - 0s 84us/step - loss: 0.6061 - accuracy: 0.6289\n",
      "Epoch 29/150\n",
      "512/512 [==============================] - 0s 84us/step - loss: 0.6059 - accuracy: 0.6289\n",
      "Epoch 30/150\n",
      "512/512 [==============================] - 0s 84us/step - loss: 0.5988 - accuracy: 0.6289\n",
      "Epoch 31/150\n",
      "512/512 [==============================] - 0s 84us/step - loss: 0.5940 - accuracy: 0.6289\n",
      "Epoch 32/150\n",
      "512/512 [==============================] - 0s 90us/step - loss: 0.5890 - accuracy: 0.6289\n",
      "Epoch 33/150\n",
      "512/512 [==============================] - 0s 86us/step - loss: 0.5826 - accuracy: 0.6289\n",
      "Epoch 34/150\n",
      "512/512 [==============================] - 0s 88us/step - loss: 0.5784 - accuracy: 0.6289\n",
      "Epoch 35/150\n",
      "512/512 [==============================] - 0s 87us/step - loss: 0.5717 - accuracy: 0.6289\n",
      "Epoch 36/150\n",
      "512/512 [==============================] - 0s 83us/step - loss: 0.5707 - accuracy: 0.6289\n",
      "Epoch 37/150\n",
      "512/512 [==============================] - 0s 82us/step - loss: 0.5678 - accuracy: 0.6289\n",
      "Epoch 38/150\n",
      "512/512 [==============================] - 0s 88us/step - loss: 0.5640 - accuracy: 0.6289\n",
      "Epoch 39/150\n",
      "512/512 [==============================] - 0s 85us/step - loss: 0.5562 - accuracy: 0.6289\n",
      "Epoch 40/150\n",
      "512/512 [==============================] - 0s 86us/step - loss: 0.5558 - accuracy: 0.6289\n",
      "Epoch 41/150\n",
      "512/512 [==============================] - 0s 87us/step - loss: 0.5485 - accuracy: 0.6289\n",
      "Epoch 42/150\n",
      "512/512 [==============================] - 0s 87us/step - loss: 0.5412 - accuracy: 0.6289\n",
      "Epoch 43/150\n",
      "512/512 [==============================] - 0s 82us/step - loss: 0.5366 - accuracy: 0.6289\n",
      "Epoch 44/150\n",
      "512/512 [==============================] - 0s 82us/step - loss: 0.5367 - accuracy: 0.6289\n",
      "Epoch 45/150\n",
      "512/512 [==============================] - 0s 89us/step - loss: 0.5314 - accuracy: 0.6289\n",
      "Epoch 46/150\n",
      "512/512 [==============================] - 0s 89us/step - loss: 0.5251 - accuracy: 0.6289\n",
      "Epoch 47/150\n",
      "512/512 [==============================] - 0s 88us/step - loss: 0.5222 - accuracy: 0.6289\n",
      "Epoch 48/150\n",
      "512/512 [==============================] - 0s 87us/step - loss: 0.5136 - accuracy: 0.6289\n",
      "Epoch 49/150\n",
      "512/512 [==============================] - 0s 86us/step - loss: 0.5111 - accuracy: 0.6289\n",
      "Epoch 50/150\n",
      "512/512 [==============================] - 0s 87us/step - loss: 0.5089 - accuracy: 0.6289\n",
      "Epoch 51/150\n",
      "512/512 [==============================] - 0s 93us/step - loss: 0.5038 - accuracy: 0.6289\n",
      "Epoch 52/150\n",
      "512/512 [==============================] - 0s 109us/step - loss: 0.4988 - accuracy: 0.6289\n",
      "Epoch 53/150\n",
      "512/512 [==============================] - 0s 98us/step - loss: 0.4962 - accuracy: 0.6289\n",
      "Epoch 54/150\n",
      "512/512 [==============================] - 0s 91us/step - loss: 0.4883 - accuracy: 0.6289\n",
      "Epoch 55/150\n",
      "512/512 [==============================] - 0s 88us/step - loss: 0.4816 - accuracy: 0.6289\n",
      "Epoch 56/150\n",
      "512/512 [==============================] - 0s 89us/step - loss: 0.4766 - accuracy: 0.6289\n",
      "Epoch 57/150\n",
      "512/512 [==============================] - 0s 91us/step - loss: 0.4734 - accuracy: 0.6289\n",
      "Epoch 58/150\n",
      "512/512 [==============================] - 0s 90us/step - loss: 0.4718 - accuracy: 0.6289\n",
      "Epoch 59/150\n",
      "512/512 [==============================] - 0s 103us/step - loss: 0.4638 - accuracy: 0.6289\n",
      "Epoch 60/150\n",
      "512/512 [==============================] - 0s 92us/step - loss: 0.4610 - accuracy: 0.6289\n",
      "Epoch 61/150\n",
      "512/512 [==============================] - 0s 99us/step - loss: 0.4535 - accuracy: 0.6289\n",
      "Epoch 62/150\n",
      "512/512 [==============================] - 0s 79us/step - loss: 0.4485 - accuracy: 0.6289\n",
      "Epoch 63/150\n",
      "512/512 [==============================] - 0s 83us/step - loss: 0.4455 - accuracy: 0.6289\n",
      "Epoch 64/150\n",
      "512/512 [==============================] - 0s 98us/step - loss: 0.4425 - accuracy: 0.6289\n",
      "Epoch 65/150\n",
      "512/512 [==============================] - 0s 92us/step - loss: 0.4343 - accuracy: 0.6289\n",
      "Epoch 66/150\n",
      "512/512 [==============================] - 0s 94us/step - loss: 0.4279 - accuracy: 0.6289\n",
      "Epoch 67/150\n",
      "512/512 [==============================] - 0s 100us/step - loss: 0.4276 - accuracy: 0.6289\n",
      "Epoch 68/150\n",
      "512/512 [==============================] - 0s 90us/step - loss: 0.4164 - accuracy: 0.6289\n",
      "Epoch 69/150\n",
      "512/512 [==============================] - 0s 90us/step - loss: 0.4181 - accuracy: 0.6289\n",
      "Epoch 70/150\n",
      "512/512 [==============================] - 0s 96us/step - loss: 0.4136 - accuracy: 0.6289\n",
      "Epoch 71/150\n",
      "512/512 [==============================] - 0s 90us/step - loss: 0.4078 - accuracy: 0.6289\n",
      "Epoch 72/150\n",
      "512/512 [==============================] - 0s 99us/step - loss: 0.4046 - accuracy: 0.6289\n",
      "Epoch 73/150\n",
      "512/512 [==============================] - 0s 89us/step - loss: 0.4015 - accuracy: 0.6289\n",
      "Epoch 74/150\n",
      "512/512 [==============================] - 0s 90us/step - loss: 0.3980 - accuracy: 0.6289\n",
      "Epoch 75/150\n",
      "512/512 [==============================] - 0s 100us/step - loss: 0.3931 - accuracy: 0.6289\n",
      "Epoch 76/150\n",
      "512/512 [==============================] - 0s 90us/step - loss: 0.3893 - accuracy: 0.9570\n",
      "Epoch 77/150\n",
      "512/512 [==============================] - 0s 103us/step - loss: 0.3871 - accuracy: 0.9668\n",
      "Epoch 78/150\n",
      "512/512 [==============================] - 0s 90us/step - loss: 0.3833 - accuracy: 0.9727\n",
      "Epoch 79/150\n",
      "512/512 [==============================] - 0s 92us/step - loss: 0.3782 - accuracy: 0.9727\n",
      "Epoch 80/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 102us/step - loss: 0.3779 - accuracy: 0.9785\n",
      "Epoch 81/150\n",
      "512/512 [==============================] - 0s 116us/step - loss: 0.3730 - accuracy: 0.9785\n",
      "Epoch 82/150\n",
      "512/512 [==============================] - 0s 86us/step - loss: 0.3711 - accuracy: 0.9863\n",
      "Epoch 83/150\n",
      "512/512 [==============================] - 0s 77us/step - loss: 0.3651 - accuracy: 0.9824\n",
      "Epoch 84/150\n",
      "512/512 [==============================] - 0s 81us/step - loss: 0.3675 - accuracy: 0.9824\n",
      "Epoch 85/150\n",
      "512/512 [==============================] - 0s 81us/step - loss: 0.3624 - accuracy: 0.9863\n",
      "Epoch 86/150\n",
      "512/512 [==============================] - 0s 81us/step - loss: 0.3594 - accuracy: 0.9844\n",
      "Epoch 87/150\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.3552 - accuracy: 0.9883\n",
      "Epoch 88/150\n",
      "512/512 [==============================] - 0s 77us/step - loss: 0.3541 - accuracy: 0.9863\n",
      "Epoch 89/150\n",
      "512/512 [==============================] - 0s 81us/step - loss: 0.3480 - accuracy: 0.9863\n",
      "Epoch 90/150\n",
      "512/512 [==============================] - 0s 78us/step - loss: 0.3472 - accuracy: 0.9863\n",
      "Epoch 91/150\n",
      "512/512 [==============================] - 0s 80us/step - loss: 0.3452 - accuracy: 0.9844\n",
      "Epoch 92/150\n",
      "512/512 [==============================] - 0s 77us/step - loss: 0.3413 - accuracy: 0.9863\n",
      "Epoch 93/150\n",
      "512/512 [==============================] - 0s 80us/step - loss: 0.3380 - accuracy: 0.9863\n",
      "Epoch 94/150\n",
      "512/512 [==============================] - 0s 78us/step - loss: 0.3362 - accuracy: 0.9863\n",
      "Epoch 95/150\n",
      "512/512 [==============================] - 0s 80us/step - loss: 0.3384 - accuracy: 0.9863\n",
      "Epoch 96/150\n",
      "512/512 [==============================] - 0s 79us/step - loss: 0.3307 - accuracy: 0.9902\n",
      "Epoch 97/150\n",
      "512/512 [==============================] - 0s 78us/step - loss: 0.3284 - accuracy: 0.9863\n",
      "Epoch 98/150\n",
      "512/512 [==============================] - 0s 80us/step - loss: 0.3270 - accuracy: 0.9902\n",
      "Epoch 99/150\n",
      "512/512 [==============================] - 0s 78us/step - loss: 0.3228 - accuracy: 0.9863\n",
      "Epoch 100/150\n",
      "512/512 [==============================] - 0s 82us/step - loss: 0.3213 - accuracy: 0.9883\n",
      "Epoch 101/150\n",
      "512/512 [==============================] - 0s 81us/step - loss: 0.3193 - accuracy: 0.9883\n",
      "Epoch 102/150\n",
      "512/512 [==============================] - 0s 85us/step - loss: 0.3166 - accuracy: 0.9902\n",
      "Epoch 103/150\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.3159 - accuracy: 0.9883\n",
      "Epoch 104/150\n",
      "512/512 [==============================] - 0s 78us/step - loss: 0.3089 - accuracy: 0.9902\n",
      "Epoch 105/150\n",
      "512/512 [==============================] - 0s 74us/step - loss: 0.3094 - accuracy: 0.9902\n",
      "Epoch 106/150\n",
      "512/512 [==============================] - 0s 78us/step - loss: 0.3041 - accuracy: 0.9902\n",
      "Epoch 107/150\n",
      "512/512 [==============================] - 0s 73us/step - loss: 0.3036 - accuracy: 0.9902\n",
      "Epoch 108/150\n",
      "512/512 [==============================] - 0s 80us/step - loss: 0.3056 - accuracy: 0.9902\n",
      "Epoch 109/150\n",
      "512/512 [==============================] - 0s 75us/step - loss: 0.2948 - accuracy: 0.9883\n",
      "Epoch 110/150\n",
      "512/512 [==============================] - 0s 84us/step - loss: 0.2986 - accuracy: 0.9902\n",
      "Epoch 111/150\n",
      "512/512 [==============================] - 0s 79us/step - loss: 0.2938 - accuracy: 0.9902\n",
      "Epoch 112/150\n",
      "512/512 [==============================] - 0s 77us/step - loss: 0.2961 - accuracy: 0.9902\n",
      "Epoch 113/150\n",
      "512/512 [==============================] - 0s 83us/step - loss: 0.2986 - accuracy: 0.9902\n",
      "Epoch 114/150\n",
      "512/512 [==============================] - 0s 81us/step - loss: 0.2941 - accuracy: 0.9883\n",
      "Epoch 115/150\n",
      "512/512 [==============================] - 0s 79us/step - loss: 0.2924 - accuracy: 0.9902\n",
      "Epoch 116/150\n",
      "512/512 [==============================] - 0s 82us/step - loss: 0.2908 - accuracy: 0.9902\n",
      "Epoch 117/150\n",
      "512/512 [==============================] - 0s 77us/step - loss: 0.2869 - accuracy: 0.9902\n",
      "Epoch 118/150\n",
      "512/512 [==============================] - 0s 81us/step - loss: 0.2852 - accuracy: 0.9902\n",
      "Epoch 119/150\n",
      "512/512 [==============================] - 0s 81us/step - loss: 0.2842 - accuracy: 0.9902\n",
      "Epoch 120/150\n",
      "512/512 [==============================] - 0s 80us/step - loss: 0.2781 - accuracy: 0.9902\n",
      "Epoch 121/150\n",
      "512/512 [==============================] - 0s 80us/step - loss: 0.2838 - accuracy: 0.9902\n",
      "Epoch 122/150\n",
      "512/512 [==============================] - 0s 79us/step - loss: 0.2784 - accuracy: 0.9902\n",
      "Epoch 123/150\n",
      "512/512 [==============================] - 0s 80us/step - loss: 0.2802 - accuracy: 0.9902\n",
      "Epoch 124/150\n",
      "512/512 [==============================] - 0s 82us/step - loss: 0.2777 - accuracy: 0.9902\n",
      "Epoch 125/150\n",
      "512/512 [==============================] - 0s 88us/step - loss: 0.2749 - accuracy: 0.9902\n",
      "Epoch 126/150\n",
      "512/512 [==============================] - 0s 81us/step - loss: 0.2752 - accuracy: 0.9902\n",
      "Epoch 127/150\n",
      "512/512 [==============================] - 0s 80us/step - loss: 0.2743 - accuracy: 0.9902\n",
      "Epoch 128/150\n",
      "512/512 [==============================] - 0s 81us/step - loss: 0.2739 - accuracy: 0.9902\n",
      "Epoch 129/150\n",
      "512/512 [==============================] - 0s 82us/step - loss: 0.2671 - accuracy: 0.9902\n",
      "Epoch 130/150\n",
      "512/512 [==============================] - 0s 80us/step - loss: 0.2675 - accuracy: 0.9883\n",
      "Epoch 131/150\n",
      "512/512 [==============================] - 0s 77us/step - loss: 0.2642 - accuracy: 0.9902\n",
      "Epoch 132/150\n",
      "512/512 [==============================] - 0s 82us/step - loss: 0.2645 - accuracy: 0.9902\n",
      "Epoch 133/150\n",
      "512/512 [==============================] - 0s 80us/step - loss: 0.2631 - accuracy: 0.9902\n",
      "Epoch 134/150\n",
      "512/512 [==============================] - 0s 82us/step - loss: 0.2609 - accuracy: 0.9902\n",
      "Epoch 135/150\n",
      "512/512 [==============================] - 0s 81us/step - loss: 0.2650 - accuracy: 0.9902\n",
      "Epoch 136/150\n",
      "512/512 [==============================] - 0s 81us/step - loss: 0.2616 - accuracy: 0.9902\n",
      "Epoch 137/150\n",
      "512/512 [==============================] - 0s 87us/step - loss: 0.2561 - accuracy: 0.9902\n",
      "Epoch 138/150\n",
      "512/512 [==============================] - 0s 81us/step - loss: 0.2557 - accuracy: 0.9902\n",
      "Epoch 139/150\n",
      "512/512 [==============================] - 0s 79us/step - loss: 0.2539 - accuracy: 0.9902\n",
      "Epoch 140/150\n",
      "512/512 [==============================] - 0s 82us/step - loss: 0.2545 - accuracy: 0.9902\n",
      "Epoch 141/150\n",
      "512/512 [==============================] - 0s 82us/step - loss: 0.2572 - accuracy: 0.9902\n",
      "Epoch 142/150\n",
      "512/512 [==============================] - 0s 82us/step - loss: 0.2474 - accuracy: 0.9902\n",
      "Epoch 143/150\n",
      "512/512 [==============================] - 0s 84us/step - loss: 0.2520 - accuracy: 0.9902\n",
      "Epoch 144/150\n",
      "512/512 [==============================] - 0s 82us/step - loss: 0.2452 - accuracy: 0.9902\n",
      "Epoch 145/150\n",
      "512/512 [==============================] - 0s 80us/step - loss: 0.2467 - accuracy: 0.9902\n",
      "Epoch 146/150\n",
      "512/512 [==============================] - 0s 85us/step - loss: 0.2434 - accuracy: 0.9902\n",
      "Epoch 147/150\n",
      "512/512 [==============================] - 0s 85us/step - loss: 0.2470 - accuracy: 0.9902\n",
      "Epoch 148/150\n",
      "512/512 [==============================] - 0s 91us/step - loss: 0.2436 - accuracy: 0.9902\n",
      "Epoch 149/150\n",
      "512/512 [==============================] - 0s 80us/step - loss: 0.2464 - accuracy: 0.9902\n",
      "Epoch 150/150\n",
      "512/512 [==============================] - 0s 87us/step - loss: 0.2358 - accuracy: 0.9902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a51ffc6d0>"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(x_train, y_train, batch_size=100, epochs=150)\n",
    "# Long scroll ahead but worth\n",
    "# The batch size and number of epochs have been set using trial and error. Still looking for more efficient ways. Open to suggestions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(x_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35,  0],\n",
       "       [ 0, 22]])"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our accuracy is 100.0%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Our accuracy is {}%\".format(((cm[0][0] + cm[1][1])/57)*100))\n",
    "sns.heatmap(cm,annot=True)\n",
    "plt.savefig('h.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Predicted  Actual\n",
       "0           1       1\n",
       "1           0       0\n",
       "2           0       0\n",
       "3           0       0\n",
       "4           0       0\n",
       "5           0       0\n",
       "6           0       0\n",
       "7           0       0\n",
       "8           0       0\n",
       "9           0       0\n",
       "10          0       0\n",
       "11          0       0\n",
       "12          0       0\n",
       "13          0       0\n",
       "14          0       0\n",
       "15          1       1\n",
       "16          0       0\n",
       "17          1       1\n",
       "18          1       1\n",
       "19          1       1\n",
       "20          1       1\n",
       "21          1       1\n",
       "22          0       0\n",
       "23          0       0\n",
       "24          1       1\n",
       "25          0       0\n",
       "26          0       0\n",
       "27          1       1\n",
       "28          0       0\n",
       "29          1       1\n",
       "30          0       0\n",
       "31          1       1\n",
       "32          0       0\n",
       "33          1       1\n",
       "34          0       0\n",
       "35          1       1\n",
       "36          0       0\n",
       "37          1       1\n",
       "38          0       0\n",
       "39          1       1\n",
       "40          1       1\n",
       "41          0       0\n",
       "42          1       1\n",
       "43          0       0\n",
       "44          0       0\n",
       "45          1       1\n",
       "46          0       0\n",
       "47          0       0\n",
       "48          0       0\n",
       "49          1       1\n",
       "50          1       1\n",
       "51          1       1\n",
       "52          1       1\n",
       "53          0       0\n",
       "54          0       0\n",
       "55          0       0\n",
       "56          0       0"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = pd.DataFrame(y_pred,columns=[\"Predicted\"])\n",
    "prediction['Predicted'] = prediction['Predicted'].map({True: 1, False: 0})\n",
    "actual = pd.DataFrame(y_test,columns=[\"Actual\"])\n",
    "df_predict = pd.concat([prediction,actual],axis=1)\n",
    "df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.692892</td>\n",
       "      <td>0.553846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.691924</td>\n",
       "      <td>0.637363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.690774</td>\n",
       "      <td>0.637363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.689057</td>\n",
       "      <td>0.641758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.686691</td>\n",
       "      <td>0.661538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.029094</td>\n",
       "      <td>0.991209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.028944</td>\n",
       "      <td>0.991209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.028805</td>\n",
       "      <td>0.991209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.028677</td>\n",
       "      <td>0.991209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.028464</td>\n",
       "      <td>0.991209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy\n",
       "0    0.692892  0.553846\n",
       "1    0.691924  0.637363\n",
       "2    0.690774  0.637363\n",
       "3    0.689057  0.641758\n",
       "4    0.686691  0.661538\n",
       "..        ...       ...\n",
       "145  0.029094  0.991209\n",
       "146  0.028944  0.991209\n",
       "147  0.028805  0.991209\n",
       "148  0.028677  0.991209\n",
       "149  0.028464  0.991209\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loss = pd.DataFrame(model.history.history)\n",
    "df_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a51161410>"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de3xU9Z3/8ddnZnIhVxISrkEJFyvIRSSgYkW8rMVu1Xqr8qtWWavb3dru/tza6lq73do+2uruutvW6vLrqnVdq1Zry7ZWV6wWXaAQvICAyEWEcJGEQLiE3Ga+vz/OJAwhIWMyyZnL+/l45DFzzvnOyScH8j4n33PO95hzDhERSX0BvwsQEZHEUKCLiKQJBbqISJpQoIuIpAkFuohImgj59Y3LysrcmDFj/Pr2IiIpadWqVXXOufKulvkW6GPGjKG6utqvby8ikpLM7MPulqnLRUQkTSjQRUTShAJdRCRN9BjoZvaIme0xs3e7WW5m9iMz22Rmq83sjMSXKSIiPYnnCP0xYN4Jll8CTIh+3Qo81PeyRETk4+ox0J1zS4D6EzS5HHjceZYDg81sRKIKFBGR+CSiD30UsD1muiY67zhmdquZVZtZdW1tbQK+tYiItEvEdejWxbwux+R1zi0EFgJUVVVp3N5kFIlAy6EB+l5tsHsN7HwLWg4PzPcUSQafmAejZiR8tYkI9BpgdMx0BbAzAeuVSAT2f+gFX49t22DPOtjxJjQf6N33a9gBO6qhqaF3n++Tro4LRNJU4fCkDfRFwG1m9hRwJtDgnNuVgPWmr0N7YPsKqFkJtRvARY5v09oIu975+OEcyoVBJb2ra1ApTPosDBkPNgBXtJpB2SegYkbvaxaRDj0Gupn9ApgLlJlZDfAPQBaAc+5h4AXg08AmoBFY0F/Fpoy9m2HD76FmBezrdJfukXrYv817H8iCslMgmHX8OoJZMPkqGDkdsvPj+75DxsOw07pen4ikvR4D3Tk3v4flDvhywipKVQ07vABf/YwX5jgYfJIX2BY82q50LMy6FSpmwYhpkJXrW8kikl58G5wr6RzaA6ufhuwCqJgJBUOPLnMR2Lsp2k1S7XWVHI69Sifm/G7eEJhzB8y4CYq7vNhHRKRfKNDDbfDinfDmzyHc0nP70nEw/kIoruCYE3n5ZVBRBcOmQCi738oVEemOAv2178PK/wdnfAFmfxUCQahZBc2drvQoHu0dueeV+lOniEgPMjvQNy6G1/8Jpl8Pl/346PzSsf7VJCLSS5kX6I318LOLoLHOu5ll6CS45H6/qxIR6bPMC/Q1v4T6zd5Jy5xC74qT7Dy/qxIR6bPMC/S3nvAuF7z03/yuREQkoTLrARe718Du1XD69X5XIiKScJkV6G8/CcFsmHK135WIiCRc5gR6W4t349AnLtGlhyKSljIn0Hesgsa9MOUavysREekXmRPoNSu919Fn+VuHiEg/yZxA31HtDZZVUO53JSIi/SJzAr1mlXfrvohImsqMQD+4Gw7UwKgqvysREek3mRHoNdXea4UCXUTSV4YE+krv6UDDp/pdiYhIv8mMQN+xCoZP1tOBRCStpX+gR8Kw8y31n4tI2kv/QK/bCC2HYNQMvysREelX6R/oB3Z4ryVjfC1DRKS/pX+gH67zXvPL/K1DRKSfpX+gNyrQRSQzpH+gH66DQAhyB/tdiYhIv8qAQK+FvDIw87sSEZF+lf6B3rhX3S0ikhHSP9AP1yrQRSQjZECg13ldLiIiaS4zAl1H6CKSAdI70NuaoeWgAl1EMkJ6B3r7TUXqchGRDJDmgV7rvebrsXMikv7iCnQzm2dmG8xsk5nd2cXyk8zsVTN7y8xWm9mnE19qL+guURHJID0GupkFgQeBS4BJwHwzm9Sp2TeBZ5xz04HrgJ8mutBe6RjHRUfoIpL+4jlCnwVscs5tcc61AE8Bl3dq44Ci6PtiYGfiSuyDjj70If7WISIyAEJxtBkFbI+ZrgHO7NTm28D/mNlXgHzgooRU11eHa71Hz+UW+12JiEi/i+cIvatBUFyn6fnAY865CuDTwH+a2XHrNrNbzazazKpra2s/frUfV2P0GnSN4yIiGSCeQK8BRsdMV3B8l8rNwDMAzrllQC5w3JlI59xC51yVc66qvHwA+rUPaxwXEckc8QT6SmCCmVWaWTbeSc9FndpsAy4EMLOJeIE+AIfgPWgfaVFEJAP0GOjOuTbgNuAlYD3e1Sxrzew7ZnZZtNnfAbeY2TvAL4CbnHOdu2UGXqNu+xeRzBHPSVGccy8AL3Sa962Y9+uAcxJbWgIcrtMliyKSMdL3TtHWJmg5pEsWRSRjpG+gN+qmIhHJLOkb6B3juKgPXUQyQ/oG+qE93mv+UH/rEBEZIOkb6Ad3ea9FI/ytQ0RkgKRxoO8GDAqG+V2JiMiASN9AP7DTOyEazPK7EhGRAZG+gX5wNxQO97sKEZEBk8aBvhMK1X8uIpkjjQN9t06IikhGSc9AD7d616HrCF1EMkh6BvrB3d6r+tBFJIOkeaCP9LcOEZEBlKaBHr2pSEfoIpJB0jzQ1YcuIpkjrvHQk8n2+kZ27j/CiOJBDC3KITcreHyjg7u8h0Nr6FwRySApF+i/Xb2LH774Xsd0SV4WIwcPYsLQAk4dUcSMk0s4o2EnwcLhEEjPP0BERLqScoF+5RmjmDyqiN0NTd7XgSZq9h1hxQf1/Ppt79nVT2avZUReIVs37GHuKeWYmc9Vi4j0v5QL9GFFuQwryu1yWf3hFqq31jN+0SHeaRrGLY+u5PTRg7nnM5OYcXLJAFcqIjKw0qpPojQ/m4tPG85Q6rlg5jTuu3oqO/cf4aqHlvLP/7OBSMT/51aLiPSXtAp0AJoPQfMBgkUj+FzVaF792lw+V1XBj/+widt+8SZNrWG/KxQR6Rcp1+XSo/abioq8m4ryc0L88KqpnDKskO+9sJ7c0Br++XPT1K8uImkn/QK9Ybv3GnNTkZnxxXPHcrg5zAOL32f6ySXccNbJPhUoItI/0q/LZdVjkF0II6Ydt+grF4zn/E+U853/Xsu7OxoGvjYRkX6UXoH+0VpY92s460sw6PirWgIB44FrT6d4UBbf/d06nNNJUhFJH+kV6K/9AHKK4Ky/7rbJ4Lxsbjt/PMu31PP6xroBLE5EpH+lR6A3H4LlD8H6RXDmlyCv9ITN5595EhUlg7jvpfd0KaOIpI3UPSm6fQX85jaItMKhWmg5CCfNhrO/3ONHc0JBbv+zU7j9mXf4n3W7mTdZg3iJSOpL3SP0zX+Aug0wagZMuRpufhn+4vcwaHBcH7/89FFUlAziieXb+rlQEZGBkbpH6A3boWA4XPWzXn08GDA+VzWaf3n5fbbXNzK6NC/BBYqIDKzUPULfvx0Gj+7TKq6eUUHA4OmV2xNUlIiIf1I30BtqoLiiT6sYOXgQ551Szi9XbactHElQYSIi/ogr0M1snpltMLNNZnZnN20+Z2brzGytmT2Z2DI7iUSigd63I3SAa2eexEcHmvnj+7UJKExExD89BrqZBYEHgUuAScB8M5vUqc0E4C7gHOfcacDf9kOtRzXWQbg5IYF+4cShDM7L4nerdyWgMBER/8RzhD4L2OSc2+KcawGeAi7v1OYW4EHn3D4A59yexJbZyf5on3cf+9ABsoIBLjh1KK+8t4dWdbuISAqLJ9BHAbFnDWui82KdApxiZv9rZsvNbF6iCuxS+wBcfexDb3fxpGE0HGll5db6hKxPRMQP8QR6V+PMdr69MgRMAOYC84GfmdlxF4Sb2a1mVm1m1bW1feizbqjxXhPQ5QJw7oRyskMBXl73UULWJyLih3gCvQaITc4KYGcXbX7jnGt1zn0AbMAL+GM45xY656qcc1Xl5eW9rdk7Qs8uhNzi3q8jRn5OiE+OL+PldR9pwC4RSVnx3Fi0EphgZpXADuA64P90avNrvCPzx8ysDK8LZksiCz1G+yWLCXxIxcWThvGH9/bw3u6DTBxRlLD1imSq1tZWampqaGpq8ruUlJSbm0tFRQVZWVlxf6bHQHfOtZnZbcBLQBB4xDm31sy+A1Q75xZFl11sZuuAMHCHc25vr36KeOzflpATorEunDgMszUsXveRAl0kAWpqaigsLGTMmDF6QtjH5Jxj79691NTUUFlZGffn4roO3Tn3gnPuFOfcOOfc96LzvhUNc5zndufcJOfcFOfcU736KeKVgJuKOisvzGHSiCKWbu6//ZBIJmlqamLIkCEK814wM4YMGfKx/7pJvTtFWw7DkfqEnRCNNXvcEFZt26cHSYskiMK893qz7VIv0BN8hUus2ePKaGmL8OaH+xK+bhEZeAUFBX6XMKBSL9ATeFNRZzMrSwkGTN0uIpKSUi/QE3xTUayCnBBTK4pZulmPphNJJ8457rjjDiZPnsyUKVN4+umnAdi1axdz5szh9NNPZ/Lkybz++uuEw2FuuummjrYPPPCAz9XHL/XGQw/lwrApUNg/TxmaPW4ID/9xC4ea2yjISb3NI5KM/vG/17Ju54GErnPSyCL+4dLT4mr7q1/9irfffpt33nmHuro6Zs6cyZw5c3jyySf51Kc+xd133004HKaxsZG3336bHTt28O677wKwf//+hNbdn1LvCP30+fBXb0Ag2C+rnz2ujHDEsfIDDQMgki7eeOMN5s+fTzAYZNiwYZx33nmsXLmSmTNn8uijj/Ltb3+bNWvWUFhYyNixY9myZQtf+cpXePHFFykqSp3LmHUI2smMk0vIDgZYurmO808d6nc5Imkh3iPp/tLdHeBz5sxhyZIl/O53v+OGG27gjjvu4Atf+ALvvPMOL730Eg8++CDPPPMMjzzyyABX3Dupd4Tez3KzgkwbXczKrbrSRSRdzJkzh6effppwOExtbS1Llixh1qxZfPjhhwwdOpRbbrmFm2++mTfffJO6ujoikQhXXXUV9957L2+++abf5cdNR+hdmDmmlIVLttDY0kZetjaRSKq74oorWLZsGdOmTcPMuO+++xg+fDg///nPuf/++8nKyqKgoIDHH3+cHTt2sGDBAiIRbzjt73//+z5XHz/zazCqqqoqV11d7cv37smr7+1hwWMrefKLZzJ7fJnf5YikpPXr1zNx4kS/y0hpXW1DM1vlnKvqqr26XLpwxsklmMEKjY8uIilEgd6F4kFZnDq8iGr1o4tIClGgd2PWmBLe3LaPNj2WTkRShAK9GzMrS2lsCbM2wTdDiIj0FwV6N2aOKQXQc0ZFJGUo0LsxrCiXk0rzFOgikjIU6Ccwc0wp1Vv36TmjIpISFOgnMKuyhL2HW9hce9jvUkQkSbW1tfldQgcF+glURfvRq9XtIpKSPvvZzzJjxgxOO+00Fi5cCMCLL77IGWecwbRp07jwwgsBOHToEAsWLGDKlClMnTqV5557Djj2ARnPPvssN910EwA33XQTt99+O+effz7f+MY3WLFiBbNnz2b69OnMnj2bDRs2ABAOh/na177Wsd4f//jHvPLKK1xxxRUd63355Ze58sorE/Lz6r72Exhblk9ZQTYrttZz3ayT/C5HJHX9/k7YvSax6xw+BS75wQmbPPLII5SWlnLkyBFmzpzJ5Zdfzi233MKSJUuorKykvt47WLv33nspLi5mzRqvxn37er4H5f3332fx4sUEg0EOHDjAkiVLCIVCLF68mL//+7/nueeeY+HChXzwwQe89dZbhEIh6uvrKSkp4ctf/jK1tbWUl5fz6KOPsmDBgr5vDxToJ2RmVJ1cqhOjIinqRz/6Ec8//zwA27dvZ+HChcyZM4fKykoASku9v8IXL17MU08dfbZ9SUlJj+u+5pprCAa9YbwbGhq48cYb2bhxI2ZGa2trx3q/9KUvEQqFjvl+N9xwA0888QQLFixg2bJlPP744wn5eRXoPZhZWcqLa3ezu6GJ4cW5fpcjkpp6OJLuD6+99hqLFy9m2bJl5OXlMXfuXKZNm9bRHRLLOdflQ5lj5zU1NR2zLD8/v+P9Pffcw/nnn8/zzz/P1q1bmTt37gnXu2DBAi699FJyc3O55pprOgK/r9SH3oNZuh5dJCU1NDRQUlJCXl4e7733HsuXL6e5uZk//vGPfPDBBwAdXS4XX3wxP/nJTzo+297lMmzYMNavX08kEuk40u/ue40aNQqAxx57rGP+xRdfzMMPP9xx4rT9+40cOZKRI0fy3e9+t6NfPhEU6D2YOKKQ/OwgK/QEI5GUMm/ePNra2pg6dSr33HMPZ511FuXl5SxcuJArr7ySadOmce211wLwzW9+k3379jF58mSmTZvGq6++CsAPfvADPvOZz3DBBRcwYkT3j738+te/zl133cU555xDOBzumP/FL36Rk046ialTpzJt2jSefPLJjmWf//znGT16NJMmTUrYz6zhc+Nw4yMr2Ln/CC/ffp7fpYikDA2fe2K33XYb06dP5+abb+62jYbP7Qezxw1h455D7DnY1HNjEZEezJgxg9WrV3P99dcndL06KRqH2eO8h1ws27yXy08f5XM1IpLqVq1a1S/r1RF6HCaNLKJ4UBZLN+31uxQRkW4p0OMQDBhnjS1l6ZY6v0sRSSkaB6n3erPtFOhxmj2ujO31R9he3+h3KSIpITc3l7179yrUe8E5x969e8nN/Xj3vqgPPU6zxw0BYOnmOq4t1TAAIj2pqKigpqaG2tpav0tJSbm5uVRUVHyszyjQ4zR+aAHlhTks3byXa2cq0EV6kpWV1XGLvQyMuLpczGyemW0ws01mducJ2l1tZs7MurxGMpWZGbPHDWHpZv0JKSLJqcdAN7Mg8CBwCTAJmG9mx93aZGaFwFeBPyW6yGQxe9wQag82s2nPIb9LERE5TjxH6LOATc65Lc65FuAp4PIu2t0L3Aek7d037dejL92syxdFJPnEE+ijgO0x0zXReR3MbDow2jn32wTWlnRGl+ZRUTKI/92kyxdFJPnEE+jHj/0IHZ3IZhYAHgD+rscVmd1qZtVmVp2qZ75njxvC8i17CUfUjy4iySWeQK8BRsdMVwA7Y6YLgcnAa2a2FTgLWNTViVHn3ELnXJVzrqq8vLz3VfvonPFlHGhqY93OA36XIiJyjHgCfSUwwcwqzSwbuA5Y1L7QOdfgnCtzzo1xzo0BlgOXOedSYyjFj+nssUevRxcRSSY9Brpzrg24DXgJWA8845xba2bfMbPL+rvAZDO0KJfxQwt4Q/3oIpJk4rqxyDn3AvBCp3nf6qbt3L6Xldw+Ob6MX6zYRlNrmNysoN/liIgAGsulV86dUEZzW4TqrT0/GVxEZKAo0HvhrLFDyAoar29KzSt1RCQ9KdB7IT8nxBknlfD6++pHF5HkoUDvpTmnlLNu1wFqDzb7XYqICKBA77VzJ3jDAOiuURFJFgr0XjptZDEleVks2ah+dBFJDgr0XgoGjNnjy3hjY52G0xWRpKBA74M5E8rYc7CZ9z/ScLoi4j8Feh98coI3Hs3r6nYRkSSgQO+DUYMHMa48nyUbdWJURPynQO+jcyeU86cte2lqDftdiohkOAV6H805xRsGYNWHGgZARPylQO+jMyu9YQB0+aKI+E2B3kcaBkBEkoUCPQE0DICIJAMFegJoGAARSQYK9ARoHwbgdV2+KCI+UqAnQDBgnDO+jNc31moYABHxjQI9Qc7VMAAi4jMFeoJoGAAR8ZsCPUE0DICI+E2BnkDnTihnxQcaBkBE/KFAT6A5p5TR1KphAETEHwr0BNIwACLiJwV6AmkYABHxkwI9wTQMgIj4RYGeYO3DACzdrKN0ERlYCvQEax8GYIm6XURkgCnQE6x9GIAlG2uJRDQMgIgMHAV6P7jg1KHUHmxmzY4Gv0sRkQyiQO8H539iKAGDV9Z/5HcpIpJBFOj9oCQ/m6qTS3l5/R6/SxGRDKJA7ycXTRrK+l0H2LH/iN+liEiGiCvQzWyemW0ws01mdmcXy283s3VmttrMXjGzkxNfamq5cOIwQN0uIjJwegx0MwsCDwKXAJOA+WY2qVOzt4Aq59xU4FngvkQXmmrGlRcwtiyfxep2EZEBEs8R+ixgk3Nui3OuBXgKuDy2gXPuVedcY3RyOVCR2DJT00WThrFscx0NR1r9LkVEMkA8gT4K2B4zXROd152bgd93tcDMbjWzajOrrq1N/wGs5k0eTmvYqdtFRAZEPIFuXczr8o4ZM7seqALu72q5c26hc67KOVdVXl4ef5UpavrowYwszuWFNbv8LkVEMkA8gV4DjI6ZrgB2dm5kZhcBdwOXOec0MhVgZsybPIIl79dxsEndLiLSv+IJ9JXABDOrNLNs4DpgUWwDM5sO/DtemOssYIw/nzqclnCEV3RyVET6WY+B7pxrA24DXgLWA88459aa2XfM7LJos/uBAuCXZva2mS3qZnUZZ/roEoYXqdtFRPpfKJ5GzrkXgBc6zftWzPuLElxX2ggEjHmTh/Pkim3sb2xhcF623yWJSJrSnaID4NqZo2lpi/Dsqhq/SxGRNKZAHwATRxRRdXIJTyz/UEPqiki/UaAPkBvOPpmtext5Y5MefCEi/UOBPkDmTR7OkPxsnlj+od+liEiaUqAPkJxQkM/NHM3i9R+xpfaQ3+WISBpSoA+gvzinkuxQgB//YZPfpYhIGlKgD6Dywhy+cPYYfvP2Djbt0VG6iCSWAn2A/eWcseRmBfnRKxv9LkVE0owCfYANKcjhxtlj+O/VO3lz2z6/yxGRNKJA98Ffzx3HiKJcvvHsaprbwn6XIyJpQoHug8LcLL53xRQ27jnEg69u9rscEUkTCnSfnH/qUK6YPoqfvrqJFR/U+12OiKQBBbqPvn3paZxUmseXnljF9vrGnj8gInICCnQfFedl8bMbq2gLR7j55yupP9zid0kiksIU6D4bW17Aw9fP4MO9jVz90FIdqYtIrynQk8Ds8WU88cUzqTvUzJUPLeX1jen/AG0RSTwFepKYOaaUZ/9qNoW5IW74jxXc+dxqdcGIyMeiQE8ipwwr5IWvnstfnjeWZ6q3c979r/LT1zbRcEQPmBaRnplz/jxwoaqqylVXV/vyvVPB+x8d5Ie/f49X3ttDTijAJZOH8+dTR/LJ8WUMyg76XZ6I+MTMVjnnqrpcpkBPbu/uaOCpldv4zds7OdjURk4owCfHl3HhxGHMHFPC2PICggHzu0wRGSAK9DTQ0hZh5dZ6Xl73EYvXf0TNviMADMoKcuqIQiaPLGbyqCJOG1lMZVk++TlxPf9bRFKMAj3NOOfYXHuId7Y3sHbnAd7d2cC6nQc41NzW0WZwXhYjiwcxqmQQowYPYuTgXEYNzou+DqKsIIeAjuxFUs6JAl2HcSnIzBg/tJDxQwu5aoY3LxJxfFjfyNqdDWyrb2Tn/iPs2HeEbXsbWbZ57zFhD5AdDDC0KIeyAu+rvDCbIfk5lBVkU1bYPj+bokFZFA/KIiekfnuRZKdATxOBgFFZlk9lWX6XyxuOtLJz/xEv6KNhv+dgM3WHmqnZ18jb2/dTf7iZSDd/sOVmBSiOhvvgQUeD/uhXiMF52RQPyqJoUIj8nBD52d5rXnaQnFAAM/1FINKfFOgZoj14J44o6rZNOOLY19hC3aFm6g62sPdwMweOtNLQ6Wt/Yys1+xpZt9ObPtzS8xDAoYCRlx3sCPijgR8kL/qanx0iLydEfnaQvJwQBTlBckNBcrIC5IS8nUJOx3TMvKwA2cEAoaCuwpXMpkCXDsGAdXTBMDz+z7WGI8cE/oEjrRxuDnO4pY3G5jYOt4RpbGnz5jW30djSvizMroYmDre3ib72VihgZIcCJwz+ozuGY9tkhzotyzq6AwkFLbrDMLKCAbKCRigQ6HifdcyywNH2ASMYMP1lIgNGgS59lhUMHN0R9FEk4mhqC3eEf1NbmObWCM1tEZo7v2+L0NLNfG86+j6mzYEjbV22aWoNd9vd1FeddwYdO4BAoNPOILqjCAXICnTeURihYKBjR+G9917b1xUMGKGgtxPxdiZHdyodr8Fu5nf5+aPzs4Kd2gVMJ9WTkAJdkkogYORlh8jLDlFe2PcdxMfRFo507ADadxRNrRFaw95XW8RF3zvawpGj7yMRWtscrZEIrW3t7by2beEILdH2bRFHS3Re+3KvjaM14qKfjdB4JOy1b28TXX9bJBKzXm9dfjLj+B1CzI4i0GnHEOi0PBjz1b4DCgY4bqfR9ToD3azj+B1a9+s4Wnf362iv/cR1JctfYgp0kahQtB8+f2D3I73mnCMc3XmEnSMc3bmEI462iIt59XYmbWHXaVlM2/Cx849tG+m0vvZ1dTE/us7WsCMS8eo6dv0Rwg7vs2FHS1vEqz2mvo7pSIRwOHY6Zj3ReeH++rOqFwIW787I+NuLTuHSaSMTXoMCXSRFmXldJJl8RWn7Tq1z6Hc9feyOresdSeSEy731Hd2RHd2RdvWZrndWbRHH4LysftkeCnQRSVkdOzW/C0kSus5LRCRNxBXoZjbPzDaY2SYzu7OL5Tlm9nR0+Z/MbEyiCxURkRPrMdDNLAg8CFwCTALmm9mkTs1uBvY558YDDwA/THShIiJyYvEcoc8CNjnntjjnWoCngMs7tbkc+Hn0/bPAhZYM1/CIiGSQeAJ9FLA9ZromOq/LNs65NqABGNJ5RWZ2q5lVm1l1ba2emykikkjxBHpXR9qdL/6Mpw3OuYXOuSrnXFV5eXk89YmISJziCfQaYHTMdAWws7s2ZhYCioH6RBQoIiLxiSfQVwITzKzSzLKB64BFndosAm6Mvr8a+IPz68kZIiIZKq4nFpnZp4F/BYLAI86575nZd4Bq59wiM8sF/hOYjndkfp1zbksP66wFPuxl3WVAXS8/O1BUY2KoxsRI9hqTvT5InhpPds512Wft2yPo+sLMqrt7BFOyUI2JoRoTI9lrTPb6IDVq1J2iIiJpQoEuIpImUjXQF/pdQBxUY2KoxsRI9hqTvT5IgRpTsg9dRESOl6pH6CIi0okCXUQkTaRcoPc0lK8fzGy0mb1qZuvNbK2Z/U10fqmZvWxmG6OvJT7XGTSzt8zst9Hpyuhwxxujwx9n+1zfYDN71szei27Ls5NwG/7f6L/xu2b2CzPL9Xs7mtkjZrbHzN6NmdfldjPPj6K/P6vN7KQDrkYAAAPWSURBVAwfa7w/+m+92syeN7PBMcvuita4wcw+5VeNMcu+ZmbOzMqi075sx56kVKDHOZSvH9qAv3POTQTOAr4cretO4BXn3ATglei0n/4GWB8z/UPggWh9+/CGQfbTvwEvOudOBabh1Zo029DMRgFfBaqcc5PxbrS7Dv+342PAvE7zuttulwATol+3Ag/5WOPLwGTn3FTgfeAugOjvznXAadHP/DT6u+9HjZjZaODPgG0xs/3ajifmnEuZL+Bs4KWY6buAu/yuq4s6f4P3H2ADMCI6bwSwwceaKvB+sS8Afos3oFodEOpq2/pQXxHwAdET9THzk2kbto8qWor3+MbfAp9Khu0IjAHe7Wm7Af8OzO+q3UDX2GnZFcB/Rd8f83sNvASc7VeNeEOCTwO2AmV+b8cTfaXUETrxDeXrq+jTmqYDfwKGOed2AURfh/pXGf8KfB2IRKeHAPudN9wx+L8txwK1wKPRbqGfmVk+SbQNnXM7gH/CO1LbhTdM9CqSazu26267Jevv0F8Av4++T5oazewyYIdz7p1Oi5KmxlipFuhxDdPrFzMrAJ4D/tY5d8DvetqZ2WeAPc65VbGzu2jq57YMAWcADznnpgOH8b+L6hjRfujLgUpgJJCP96d3Z0nzf7ILyfbvjpndjddt+V/ts7poNuA1mlkecDfwra4WdzHP93/3VAv0eIby9YWZZeGF+X85534Vnf2RmY2ILh8B7PGpvHOAy8xsK94Tpy7AO2IfHB3uGPzfljVAjXPuT9HpZ/ECPlm2IcBFwAfOuVrnXCvwK2A2ybUd23W33ZLqd8jMbgQ+A3zeRfsuSJ4ax+HtvN+J/u5UAG+a2XCSp8ZjpFqgxzOU74AzMwP+A1jvnPuXmEWxwwrfiNe3PuCcc3c55yqcc2PwttkfnHOfB17FG+7Y1/oAnHO7ge1m9onorAuBdSTJNozaBpxlZnnRf/P2GpNmO8bobrstAr4QvUrjLKChvWtmoJnZPOAbwGXOucaYRYuA68x7+Hwl3onHFQNdn3NujXNuqHNuTPR3pwY4I/p/NWm24zH87sTvxUmLT+OdEd8M3O13PdGaPon359Zq4O3o16fx+qlfATZGX0uToNa5wG+j78fi/aJsAn4J5Phc2+lAdXQ7/hooSbZtCPwj8B7wLt6Q0Tl+b0fgF3h9+q14oXNzd9sNr6vgwejvzxq8K3b8qnETXj90++/MwzHt747WuAG4xK8aOy3fytGTor5sx56+dOu/iEiaSLUuFxER6YYCXUQkTSjQRUTShAJdRCRNKNBFRNKEAl1EJE0o0EVE0sT/Bwu48iW7CNztAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
